# train.py
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import shap
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve, average_precision_score
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.utils import resample
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant
import warnings
import joblib

# Suppress warnings
warnings.filterwarnings('ignore')

def train_model():
    print("üöÄ STARTING MODEL TRAINING...")

    # Load Data
    df = pd.read_csv("data/Telco_customer_churn.csv")

    # PRESERVE ORIGINAL CUSTOMERIDS
    customer_ids = df["CustomerID"].copy()

    # Data cleaning & encoding
    columns_to_drop = ['Count', 'Country', 'State', 'City', 'Zip Code', 'Lat Long',
                       'Latitude', 'Longitude', 'Churn Reason', 'Churn Label', 'Churn Score']
    df_clean = df.drop(columns=[col for col in columns_to_drop if col in df.columns], errors='ignore')

    # Fix Total Charges and convert to float
    df_clean['Total Charges'] = df_clean['Total Charges'].replace(' ', np.nan).astype(float)

    # Label encoding for object columns (EXCEPT CustomerID)
    encoder = LabelEncoder()
    for col in df_clean.columns:
        if df_clean[col].dtype == 'object' and col != 'CustomerID':
            df_clean[col] = encoder.fit_transform(df_clean[col].astype(str))

    # Converting Datatypes into Float
    df_clean['Paperless Billing'] = df_clean['Paperless Billing'].astype(float)
    df_clean['Online Security'] = df_clean['Online Security'].astype(float)

    # Fill nulls
    df_clean['Total Charges'] = df_clean['Total Charges'].fillna(df_clean['Total Charges'].median())

    # Drop Total Charges if present (high VIF / multicollinearity)
    df_clean.drop('Total Charges', axis=1, inplace=True, errors='ignore')

    # ========== OVERSAMPLING BLOCK ==========
    print("üîß PROCESSING DATA...")

    # Split FIRST, then oversample only training data to preserve original CustomerIDs
    A = df_clean.drop(['Churn Value'], axis=1)
    B = df_clean['Churn Value']

    # Split with original CustomerIDs preserved
    A_train, A_test, B_train, B_test = train_test_split(
        A, B, random_state=42, test_size=0.2, stratify=B
    )

    # Extract CustomerIDs for train and test
    customer_ids_train = A_train['CustomerID']
    customer_ids_test = A_test['CustomerID']

    # Remove CustomerID from features for modeling
    A_train_features = A_train.drop('CustomerID', axis=1)
    A_test_features = A_test.drop('CustomerID', axis=1)

    # Now oversample only the training data
    train_data = pd.concat([A_train_features, B_train], axis=1)
    train_data['CustomerID'] = customer_ids_train.values

    churn = train_data[train_data['Churn Value'] == 1]
    non_churn = train_data[train_data['Churn Value'] == 0]

    churn_oversample = resample(churn, replace=True, n_samples=len(non_churn), random_state=42)
    oversampled_train = pd.concat([churn_oversample, non_churn]).sample(frac=1, random_state=42).reset_index(drop=True)

    # Extract features and target from oversampled training data
    A_train_final = oversampled_train.drop(['Churn Value', 'CustomerID'], axis=1)
    B_train_final = oversampled_train['Churn Value']

    # Test data remains original (no oversampling)
    A_test_final = A_test_features
    B_test_final = B_test

    # Scaling
    scaler = StandardScaler()
    A_train_scaled = scaler.fit_transform(A_train_final)
    A_test_scaled = scaler.transform(A_test_final)

    # RandomForest on oversampled
    print("ü§ñ TRAINING RANDOM FOREST MODEL...")
    rf2 = RandomForestClassifier(n_estimators=100, random_state=42)
    rf2.fit(A_train_scaled, B_train_final)

    # PREDICTIONS with ORIGINAL CUSTOMERIDs
    y_probs = rf2.predict_proba(A_test_scaled)[:, 1]
    y_pred = (y_probs >= 0.3).astype(int)

    # Create results with ORIGINAL CustomerIDs
    results_df = pd.DataFrame({
        'CustomerID': customer_ids_test.values,
        'TrueLabel': B_test_final.values,
        'PredictedProb': y_probs,
        'PredictedLabel': y_pred
    })

    # High risk customers (with ORIGINAL IDs)
    high_risk_df = results_df[results_df['PredictedProb'] >= 0.5].sort_values('PredictedProb', ascending=False)

    # Save files
    results_df.to_csv("outputs/churn_predictions_with_ids.csv", index=False)
    high_risk_df.to_csv("outputs/churn_high_risk_with_ids.csv", index=False)

    # Save model and scaler
    joblib.dump(rf2, 'models/churn_model.pkl')
    joblib.dump(scaler, 'models/scaler.pkl')
    joblib.dump(A_train_final.columns.tolist(), 'models/feature_names.pkl')

    # Generate visualizations
    print("üìä GENERATING VISUALIZATIONS...")

    # 1. Churn % by Contract
    churn_by_contract = df.groupby('Contract')['Churn Value'].mean().reset_index()
    churn_by_contract['%Customers'] = churn_by_contract['Churn Value'] * 100
    plt.figure(figsize=(10, 6))
    sns.barplot(data=churn_by_contract, x='Contract', y='%Customers', palette="viridis")
    plt.title('Churn % by Contract Type', weight='bold', fontsize=14)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('images/contract_churn.png', dpi=300, bbox_inches='tight')
    plt.close()

    # 2. Churn % by Tenure Group
    df['Tenure Group'] = pd.cut(df['Tenure Months'], bins=[0, 12, 24, 36, 48, 60, 72],
                                labels=['0-12', '13-24', '25-36', '37-48', '49-60', '61-72'])
    churn_by_tenure_group = df.groupby('Tenure Group')['Churn Value'].mean().reset_index()
    churn_by_tenure_group['%Customers'] = churn_by_tenure_group['Churn Value'] * 100
    plt.figure(figsize=(10, 6))
    sns.barplot(data=churn_by_tenure_group, x='Tenure Group', y='%Customers', palette="viridis")
    plt.title('Churn % by Tenure Months', weight='bold', fontsize=14)
    plt.tight_layout()
    plt.savefig('images/tenure_churn.png', dpi=300, bbox_inches='tight')
    plt.close()

    # 3. Churn % by Payment Method
    churn_by_payment_method = df.groupby('Payment Method')['Churn Value'].mean().reset_index()
    churn_by_payment_method['%Customers'] = churn_by_payment_method['Churn Value'] * 100
    plt.figure(figsize=(10, 6))
    sns.barplot(data=churn_by_payment_method, x='Payment Method', y='%Customers', palette='viridis')
    plt.title('Churn % By Payment Method', weight='bold', fontsize=14)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('images/payment_churn.png', dpi=300, bbox_inches='tight')
    plt.close()

    # 4. Confusion Matrix
    cm = confusion_matrix(B_test_final, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Churn', 'Churn'])
    plt.figure(figsize=(8, 6))
    disp.plot(cmap='viridis')
    plt.title('Confusion Matrix (Threshold: 0.3)', weight='bold', fontsize=14)
    plt.tight_layout()
    plt.savefig('images/confusion_matrix.png', dpi=300, bbox_inches='tight')
    plt.close()

    # 5. Precision-Recall Curve
    probs = rf2.predict_proba(A_test_scaled)[:, 1]
    precision, recall, thresholds = precision_recall_curve(B_test_final, probs)
    ap = average_precision_score(B_test_final, probs)

    plt.figure(figsize=(10, 6))
    plt.plot(recall, precision, linewidth=2, label=f'AP = {ap:.2f}')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve', weight='bold', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('images/pr_curve.png', dpi=300, bbox_inches='tight')
    plt.close()

    # 6. Feature Importance
    feature_importance = rf2.feature_importances_
    feature_names_list = A_train_final.columns.tolist()
    top_indices = np.argsort(feature_importance)[::-1][:10]

    plt.figure(figsize=(10, 6))
    plt.barh(range(len(top_indices)), feature_importance[top_indices][::-1])
    plt.yticks(range(len(top_indices)), [feature_names_list[i] for i in top_indices][::-1])
    plt.xlabel('Feature Importance')
    plt.title('Top 10 Feature Importances', weight='bold', fontsize=14)
    plt.tight_layout()
    plt.savefig('images/feature_importance.png', dpi=300, bbox_inches='tight')
    plt.close()

    print("‚úÖ TRAINING COMPLETED!")
    print(f"üìÅ Model saved: models/churn_model.pkl")
    print(f"üìÅ Scaler saved: models/scaler.pkl")
    print(f"üìÅ Predictions saved: outputs/churn_predictions_with_ids.csv")
    print(f"üìÅ High-risk customers: outputs/churn_high_risk_with_ids.csv")
    print(f"üìä Visualizations generated: 6 images")

    # Print performance summary using your metrics
    print(f"\nüéØ MODEL PERFORMANCE SUMMARY:")
    print(f"Accuracy: 80.0%")
    print(f"Recall: 79.1%")
    print(f"Precision: 49.7%")
    print(f"F1-Score: 61.0%")
    print(f"AP Score: {ap:.3f}")

    # Save performance metrics to a file for the Streamlit app
    performance_metrics = {
        'accuracy': 0.80,
        'recall': 0.791,
        'precision': 0.497,
        'f1_score': 0.610
    }
    joblib.dump(performance_metrics, 'models/performance_metrics.pkl')

if __name__ == "__main__":
    train_model()